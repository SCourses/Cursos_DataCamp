{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-query retriever\n",
    "\n",
    "![Multi-query retriever](./diagrams/slide_diagrama_03_V2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "from typing import Any\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.retrievers import MultiQueryRetriever\n",
    "from langchain.vectorstores import Chroma\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from src.langchain_docs_loader import load_langchain_docs_splitted\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3290"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = load_langchain_docs_splitted()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparaci√≥n de vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()\n",
    "vectorstore = Chroma.from_documents(documents=docs[:100], embedding=embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparaci√≥n de retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOpenAI()\n",
    "retriever=MultiQueryRetriever.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Prueba de retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multy_query\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='- [HOW to Make Conversational Form with LangChain](https://youtu.be/IT93On2LB5k)\\n- ‚õì [Claude-2 meets LangChain!](https://youtu.be/Hb_D3p0bK2U?si=j96Kc7oJoeRI5-iC)\\n- ‚õì [PaLM 2 Meets LangChain](https://youtu.be/orPwLibLqm4?si=KgJjpEbAD9YBPqT4)\\n- ‚õì [LLaMA2 with LangChain - Basics | LangChain TUTORIAL](https://youtu.be/cIRzwSXB4Rc?si=v3Hwxk1m3fksBIHN)\\n- ‚õì [Serving LLaMA2 with Replicate](https://youtu.be/JIF4nNi26DE?si=dSazFyC4UQmaR-rJ)\\n- ‚õì [NEW LangChain Expression Language](https://youtu.be/ud7HJ2p3gp0?si=8pJ9O6hGbXrCX5G9)\\n- ‚õì [Building a RCI Chain for Agents with LangChain Expression Language](https://youtu.be/QaKM5s0TnsY?si=0miEj-o17AHcGfLG)\\n- ‚õì [How to Run LLaMA-2-70B on the Together AI](https://youtu.be/Tc2DHfzHeYE?si=Xku3S9dlBxWQukpe)\\n- ‚õì [RetrievalQA with LLaMA 2 70b & Chroma DB](https://youtu.be/93yueQQnqpM?si=ZMwj-eS_CGLnNMXZ)\\n- ‚õì [How to use BGE Embeddings for LangChain](https://youtu.be/sWRvSG7vL4g?si=85jnvnmTCF9YIWXI)\\n- ‚õì [How to use Custom Prompts for RetrievalQA on LLaMA-2 7B](https://youtu.be/PDwUKves9GY?si=sMF99TWU0p4eiK80)', metadata={'description': 'Below are links to tutorials and courses on LangChain. For written guides on common use cases for LangChain, check out the use cases guides.', 'language': 'en', 'source': 'https://python.langchain.com/docs/additional_resources/tutorials', 'title': 'Tutorials | ü¶úÔ∏èüîó Langchain'}),\n",
       " Document(page_content='### LangChain How to and guides by Sam Witteveen\\u200b', metadata={'description': 'Below are links to tutorials and courses on LangChain. For written guides on common use cases for LangChain, check out the use cases guides.', 'language': 'en', 'source': 'https://python.langchain.com/docs/additional_resources/tutorials', 'title': 'Tutorials | ü¶úÔ∏èüîó Langchain'}),\n",
       " Document(page_content='## RAG Search Example\\u200b\\n\\nFor our next example, we want to run a retrieval-augmented generation\\nchain to add some context when responding to questions.\\n\\n```python\\n# Requires:\\n# pip install langchain docarray tiktoken\\n\\nfrom langchain_community.vectorstores import DocArrayInMemorySearch\\nfrom langchain_core.output_parsers import StrOutputParser\\nfrom langchain_core.prompts import ChatPromptTemplate\\nfrom langchain_core.runnables import RunnableParallel, RunnablePassthrough\\nfrom langchain_openai.chat_models import ChatOpenAI\\nfrom langchain_openai.embeddings import OpenAIEmbeddings\\n\\nvectorstore = DocArrayInMemorySearch.from_texts(\\n    [\"harrison worked at kensho\", \"bears like to eat honey\"],\\n    embedding=OpenAIEmbeddings(),\\n)\\nretriever = vectorstore.as_retriever()\\n\\ntemplate = \"\"\"Answer the question based only on the following context:\\n{context}\\n\\nQuestion: {question}\\n\"\"\"\\nprompt = ChatPromptTemplate.from_template(template)\\nmodel = ChatOpenAI()\\noutput_parser = StrOutputParser()\\n\\nsetup_and_retrieval = RunnableParallel(\\n    {\"context\": retriever, \"question\": RunnablePassthrough()}\\n)\\nchain = setup_and_retrieval | prompt | model | output_parser\\n\\nchain.invoke(\"where did harrison work?\")\\n```\\n\\nIn this case, the composed chain is:\\n\\n```python\\nchain = setup_and_retrieval | prompt | model | output_parser\\n```\\n\\nTo explain this, we first can see that the prompt template above takes\\nin `context` and `question` as values to be substituted in the prompt.\\nBefore building the prompt template, we want to retrieve relevant\\ndocuments to the search and include them as part of the context.\\n\\nAs a preliminary step, we‚Äôve setup the retriever using an in memory\\nstore, which can retrieve documents based on a query. This is a runnable\\ncomponent as well that can be chained together with other components,\\nbut you can also try to run it separately:\\n\\n```python\\nretriever.invoke(\"where did harrison work?\")\\n```\\n\\nWe then use the `RunnableParallel` to prepare the expected inputs into\\nthe prompt by using the entries for the retrieved documents as well as\\nthe original user question, using the retriever for document search, and\\nRunnablePassthrough to pass the user‚Äôs question:\\n\\n```python\\nsetup_and_retrieval = RunnableParallel(\\n    {\"context\": retriever, \"question\": RunnablePassthrough()}\\n)\\n```\\n\\nTo review, the complete chain is:\\n\\n```python\\nsetup_and_retrieval = RunnableParallel(\\n    {\"context\": retriever, \"question\": RunnablePassthrough()}\\n)\\nchain = setup_and_retrieval | prompt | model | output_parser\\n```\\n\\nWith the flow being:\\n\\n1. The first steps create a `RunnableParallel` object with two entries.\\nThe first entry, `context` will include the document results fetched\\nby the retriever. The second entry, `question` will contain the\\nuser‚Äôs original question. To pass on the question, we use\\n`RunnablePassthrough` to copy this entry.\\n\\n2. Feed the dictionary from the step above to the `prompt` component.\\nIt then takes the user input which is `question` as well as the\\nretrieved document which is `context` to construct a prompt and\\noutput a PromptValue.  \\n\\n3. The `model` component takes the generated prompt, and passes into\\nthe OpenAI LLM model for evaluation. The generated output from the\\nmodel is a `ChatMessage` object.\\n\\n4. Finally, the `output_parser` component takes in a `ChatMessage`, and\\ntransforms this into a Python string, which is returned from the\\ninvoke method.\\n\\n## Next steps\\u200b\\n\\nWe recommend reading our [Why use LCEL](/docs/expression_language/why)\\nsection next to see a side-by-side comparison of the code needed to\\nproduce common functionality with and without LCEL.', metadata={'description': 'LCEL makes it easy to build complex chains from basic components, and', 'language': 'en', 'source': 'https://python.langchain.com/docs/expression_language/get_started', 'title': 'Get started | ü¶úÔ∏èüîó Langchain'}),\n",
       " Document(page_content=\"# Cookbook\\n\\nExample code for accomplishing common tasks with the LangChain Expression Language (LCEL). These examples show how to compose different Runnable (the core LCEL interface) components to achieve various tasks. If you're just getting acquainted with LCEL, the [Prompt + LLM](/docs/expression_language/cookbook/prompt_llm_parser) page is a good place to start.\\n\\n[üìÑÔ∏è Prompt + LLMThe most common and valuable composition is taking:](/docs/expression_language/cookbook/prompt_llm_parser)[üìÑÔ∏è RAGLet‚Äôs look at adding in a retrieval step to a prompt and LLM, which adds](/docs/expression_language/cookbook/retrieval)[üìÑÔ∏è Multiple chainsRunnables can easily be used to string together multiple Chains](/docs/expression_language/cookbook/multiple_chains)[üìÑÔ∏è Querying a SQL DBWe can replicate our SQLDatabaseChain with Runnables.](/docs/expression_language/cookbook/sql_db)[üìÑÔ∏è AgentsYou can pass a Runnable into an agent.](/docs/expression_language/cookbook/agent)[üìÑÔ∏è Code writingExample of how to use LCEL to write Python code.](/docs/expression_language/cookbook/code_writing)[üìÑÔ∏è Routing by semantic similarityWith LCEL you can easily add [custom routing](/docs/expression_language/cookbook/embedding_router)[üìÑÔ∏è Adding memoryThis shows how to add memory to an arbitrary chain. Right now, you can](/docs/expression_language/cookbook/memory)[üìÑÔ∏è Adding moderationThis shows how to add in moderation (or other safeguards) around your](/docs/expression_language/cookbook/moderation)[üìÑÔ∏è Managing prompt sizeAgents dynamically call tools. The results of those tool calls are added](/docs/expression_language/cookbook/prompt_size)[üìÑÔ∏è Using toolsYou can use any Tools with Runnables easily.](/docs/expression_language/cookbook/tools)\", metadata={'description': \"Example code for accomplishing common tasks with the LangChain Expression Language (LCEL). These examples show how to compose different Runnable (the core LCEL interface) components to achieve various tasks. If you're just getting acquainted with LCEL, the Prompt + LLM page is a good place to start.\", 'language': 'en', 'source': 'https://python.langchain.com/docs/expression_language/cookbook/', 'title': 'Cookbook | ü¶úÔ∏èüîó Langchain'}),\n",
       " Document(page_content='- [LangChain In Action: Real-World Use Case With Step-by-Step Tutorial](https://youtu.be/UO699Szp82M) by [Rabbitmetrics](https://www.youtube.com/@rabbitmetrics)\\n- [Summarizing and Querying Multiple Papers with LangChain](https://youtu.be/p_MQRWH5Y6k) by [Automata Learning Lab](https://www.youtube.com/@automatalearninglab)\\n- [Using Langchain (and Replit) through Tana, ask Google/Wikipedia/Wolfram Alpha to fill out a table](https://youtu.be/Webau9lEzoI) by [Stian H√•klev](https://www.youtube.com/@StianHaklev)\\n- [Langchain PDF App (GUI) | Create a ChatGPT For Your PDF in Python](https://youtu.be/wUAUdEw5oxM) by [Alejandro AO - Software & Ai](https://www.youtube.com/@alejandro_ao)\\n- [Auto-GPT with LangChain üî• | Create Your Own Personal AI Assistant](https://youtu.be/imDfPmMKEjM) by [Data Science Basics](https://www.youtube.com/@datasciencebasics)\\n- [Create Your OWN Slack AI Assistant with Python & LangChain](https://youtu.be/3jFXRNn2Bu8) by [Dave Ebbelaar](https://www.youtube.com/@daveebbelaar)\\n- [How to Create LOCAL Chatbots with GPT4All and LangChain [Full Guide]](https://youtu.be/4p1Fojur8Zw) by [Liam Ottley](https://www.youtube.com/@LiamOttley)\\n- [Build a Multilingual PDF Search App with LangChain, Cohere and Bubble](https://youtu.be/hOrtuumOrv8) by [Menlo Park Lab](https://www.youtube.com/@menloparklab)\\n- [Building a LangChain Agent (code-free!) Using Bubble and Flowise](https://youtu.be/jDJIIVWTZDE) by [Menlo Park Lab](https://www.youtube.com/@menloparklab)\\n- [Build a LangChain-based Semantic PDF Search App with No-Code Tools Bubble and Flowise](https://youtu.be/s33v5cIeqA4) by [Menlo Park Lab](https://www.youtube.com/@menloparklab)\\n- [LangChain Memory Tutorial | Building a ChatGPT Clone in Python](https://youtu.be/Cwq91cj2Pnc) by [Alejandro AO - Software & Ai](https://www.youtube.com/@alejandro_ao)\\n- [ChatGPT For Your DATA | Chat with Multiple Documents Using LangChain](https://youtu.be/TeDgIDqQmzs) by [Data Science Basics](https://www.youtube.com/@datasciencebasics)\\n- [Llama Index: Chat with Documentation using URL Loader](https://youtu.be/XJRoDEctAwA) by [Merk](https://www.youtube.com/@merksworld)\\n- [Using OpenAI, LangChain, and Gradio to Build Custom GenAI Applications](https://youtu.be/1MsmqMg3yUc) by [David Hundley](https://www.youtube.com/@dkhundley)\\n- [LangChain, Chroma DB, OpenAI Beginner Guide | ChatGPT with your PDF](https://youtu.be/FuqdVNB_8c0)\\n- [Build AI chatbot with custom knowledge base using OpenAI API and GPT Index](https://youtu.be/vDZAZuaXf48) by [Irina Nik](https://www.youtube.com/@irina_nik)\\n- [Build Your Own Auto-GPT Apps with LangChain (Python Tutorial)](https://youtu.be/NYSWn1ipbgg) by [Dave Ebbelaar](https://www.youtube.com/@daveebbelaar)\\n- [Chat with Multiple PDFs | LangChain App Tutorial in Python (Free LLMs and Embeddings)](https://youtu.be/dXxQ0LR-3Hg) by [Alejandro AO - Software & Ai](https://www.youtube.com/@alejandro_ao)\\n- [Chat with a CSV | LangChain Agents Tutorial (Beginners)](https://youtu.be/tjeti5vXWOU) by [Alejandro AO - Software & Ai](https://www.youtube.com/@alejandro_ao)', metadata={'description': '‚õì icon marks a new addition [last update 2023-09-21]', 'language': 'en', 'source': 'https://python.langchain.com/docs/additional_resources/youtube', 'title': 'YouTube videos | ü¶úÔ∏èüîó Langchain'})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\n",
    "    \"How to create a retriever with langchain expression language?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generaci√≥n de preguntas alternativas de forma personalizada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definici√≥n de esquema de salida de preguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LineList(BaseModel):\n",
    "    # \"lines\" is the key (attribute name) of the parsed output\n",
    "    lines: list[str] = Field(description=\"Lines of text\")\n",
    "\n",
    "\n",
    "class LineListOutputParser(PydanticOutputParser[Any]):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(pydantic_object=LineList)\n",
    "\n",
    "    def parse(self, text: str) -> LineList:\n",
    "        lines = text.strip().splitlines()\n",
    "        return LineList(lines=lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creaci√≥n de `prompt` personalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an AI language assistant well versed in the Langchain Documentation.\n",
    "Your more precise task is to generate five different versions of the given question to retrieve relevant documents from a vector database.\n",
    "By generating multiple perspectives on the question, your goal is to overcome some of the limitations of the distance-based similarity search.\n",
    "\n",
    "Provide these alternative questions separed by newlines.\n",
    "\n",
    "Original question: {question}\n",
    "New questions:\"\"\"\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=ChatOpenAI(temperature=0),\n",
    "    prompt=prompt,\n",
    "    output_parser=LineListOutputParser(),\n",
    ")\n",
    "\n",
    "# In language expression language, you could create the chain with:\n",
    "# llm_chain = prompt | llm | LineListOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use de cadena de generaci√≥n de preguntas personalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How to create a retriever with langchain expression language?',\n",
       " 'text': LineList(lines=['1. What are the steps to build a retriever using the langchain expression language?', '2. Can you explain the process of constructing a retriever using the langchain expression language?', '3. What is the procedure for creating a retriever using the langchain expression language?', '4. Could you provide a guide on how to develop a retriever using the langchain expression language?', '5. What are the necessary components for implementing a retriever with the langchain expression language?'])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.invoke(\n",
    "    {\"question\": \"How to create a retriever with langchain expression language?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integraci√≥n de cadena de generaci√≥n de preguntas personalizada en `retriever`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = MultiQueryRetriever(\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    llm_chain=llm_chain,\n",
    "    parser_key=\"lines\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uso de `retriever` con cadena de generaci√≥n de preguntas personalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='- [HOW to Make Conversational Form with LangChain](https://youtu.be/IT93On2LB5k)\\n- ‚õì [Claude-2 meets LangChain!](https://youtu.be/Hb_D3p0bK2U?si=j96Kc7oJoeRI5-iC)\\n- ‚õì [PaLM 2 Meets LangChain](https://youtu.be/orPwLibLqm4?si=KgJjpEbAD9YBPqT4)\\n- ‚õì [LLaMA2 with LangChain - Basics | LangChain TUTORIAL](https://youtu.be/cIRzwSXB4Rc?si=v3Hwxk1m3fksBIHN)\\n- ‚õì [Serving LLaMA2 with Replicate](https://youtu.be/JIF4nNi26DE?si=dSazFyC4UQmaR-rJ)\\n- ‚õì [NEW LangChain Expression Language](https://youtu.be/ud7HJ2p3gp0?si=8pJ9O6hGbXrCX5G9)\\n- ‚õì [Building a RCI Chain for Agents with LangChain Expression Language](https://youtu.be/QaKM5s0TnsY?si=0miEj-o17AHcGfLG)\\n- ‚õì [How to Run LLaMA-2-70B on the Together AI](https://youtu.be/Tc2DHfzHeYE?si=Xku3S9dlBxWQukpe)\\n- ‚õì [RetrievalQA with LLaMA 2 70b & Chroma DB](https://youtu.be/93yueQQnqpM?si=ZMwj-eS_CGLnNMXZ)\\n- ‚õì [How to use BGE Embeddings for LangChain](https://youtu.be/sWRvSG7vL4g?si=85jnvnmTCF9YIWXI)\\n- ‚õì [How to use Custom Prompts for RetrievalQA on LLaMA-2 7B](https://youtu.be/PDwUKves9GY?si=sMF99TWU0p4eiK80)', metadata={'description': 'Below are links to tutorials and courses on LangChain. For written guides on common use cases for LangChain, check out the use cases guides.', 'language': 'en', 'source': 'https://python.langchain.com/docs/additional_resources/tutorials', 'title': 'Tutorials | ü¶úÔ∏èüîó Langchain'}),\n",
       " Document(page_content='### LangChain How to and guides by Sam Witteveen\\u200b', metadata={'description': 'Below are links to tutorials and courses on LangChain. For written guides on common use cases for LangChain, check out the use cases guides.', 'language': 'en', 'source': 'https://python.langchain.com/docs/additional_resources/tutorials', 'title': 'Tutorials | ü¶úÔ∏èüîó Langchain'}),\n",
       " Document(page_content=\"# Cookbook\\n\\nExample code for accomplishing common tasks with the LangChain Expression Language (LCEL). These examples show how to compose different Runnable (the core LCEL interface) components to achieve various tasks. If you're just getting acquainted with LCEL, the [Prompt + LLM](/docs/expression_language/cookbook/prompt_llm_parser) page is a good place to start.\\n\\n[üìÑÔ∏è Prompt + LLMThe most common and valuable composition is taking:](/docs/expression_language/cookbook/prompt_llm_parser)[üìÑÔ∏è RAGLet‚Äôs look at adding in a retrieval step to a prompt and LLM, which adds](/docs/expression_language/cookbook/retrieval)[üìÑÔ∏è Multiple chainsRunnables can easily be used to string together multiple Chains](/docs/expression_language/cookbook/multiple_chains)[üìÑÔ∏è Querying a SQL DBWe can replicate our SQLDatabaseChain with Runnables.](/docs/expression_language/cookbook/sql_db)[üìÑÔ∏è AgentsYou can pass a Runnable into an agent.](/docs/expression_language/cookbook/agent)[üìÑÔ∏è Code writingExample of how to use LCEL to write Python code.](/docs/expression_language/cookbook/code_writing)[üìÑÔ∏è Routing by semantic similarityWith LCEL you can easily add [custom routing](/docs/expression_language/cookbook/embedding_router)[üìÑÔ∏è Adding memoryThis shows how to add memory to an arbitrary chain. Right now, you can](/docs/expression_language/cookbook/memory)[üìÑÔ∏è Adding moderationThis shows how to add in moderation (or other safeguards) around your](/docs/expression_language/cookbook/moderation)[üìÑÔ∏è Managing prompt sizeAgents dynamically call tools. The results of those tool calls are added](/docs/expression_language/cookbook/prompt_size)[üìÑÔ∏è Using toolsYou can use any Tools with Runnables easily.](/docs/expression_language/cookbook/tools)\", metadata={'description': \"Example code for accomplishing common tasks with the LangChain Expression Language (LCEL). These examples show how to compose different Runnable (the core LCEL interface) components to achieve various tasks. If you're just getting acquainted with LCEL, the Prompt + LLM page is a good place to start.\", 'language': 'en', 'source': 'https://python.langchain.com/docs/expression_language/cookbook/', 'title': 'Cookbook | ü¶úÔ∏èüîó Langchain'}),\n",
       " Document(page_content='## RAG Search Example\\u200b\\n\\nFor our next example, we want to run a retrieval-augmented generation\\nchain to add some context when responding to questions.\\n\\n```python\\n# Requires:\\n# pip install langchain docarray tiktoken\\n\\nfrom langchain_community.vectorstores import DocArrayInMemorySearch\\nfrom langchain_core.output_parsers import StrOutputParser\\nfrom langchain_core.prompts import ChatPromptTemplate\\nfrom langchain_core.runnables import RunnableParallel, RunnablePassthrough\\nfrom langchain_openai.chat_models import ChatOpenAI\\nfrom langchain_openai.embeddings import OpenAIEmbeddings\\n\\nvectorstore = DocArrayInMemorySearch.from_texts(\\n    [\"harrison worked at kensho\", \"bears like to eat honey\"],\\n    embedding=OpenAIEmbeddings(),\\n)\\nretriever = vectorstore.as_retriever()\\n\\ntemplate = \"\"\"Answer the question based only on the following context:\\n{context}\\n\\nQuestion: {question}\\n\"\"\"\\nprompt = ChatPromptTemplate.from_template(template)\\nmodel = ChatOpenAI()\\noutput_parser = StrOutputParser()\\n\\nsetup_and_retrieval = RunnableParallel(\\n    {\"context\": retriever, \"question\": RunnablePassthrough()}\\n)\\nchain = setup_and_retrieval | prompt | model | output_parser\\n\\nchain.invoke(\"where did harrison work?\")\\n```\\n\\nIn this case, the composed chain is:\\n\\n```python\\nchain = setup_and_retrieval | prompt | model | output_parser\\n```\\n\\nTo explain this, we first can see that the prompt template above takes\\nin `context` and `question` as values to be substituted in the prompt.\\nBefore building the prompt template, we want to retrieve relevant\\ndocuments to the search and include them as part of the context.\\n\\nAs a preliminary step, we‚Äôve setup the retriever using an in memory\\nstore, which can retrieve documents based on a query. This is a runnable\\ncomponent as well that can be chained together with other components,\\nbut you can also try to run it separately:\\n\\n```python\\nretriever.invoke(\"where did harrison work?\")\\n```\\n\\nWe then use the `RunnableParallel` to prepare the expected inputs into\\nthe prompt by using the entries for the retrieved documents as well as\\nthe original user question, using the retriever for document search, and\\nRunnablePassthrough to pass the user‚Äôs question:\\n\\n```python\\nsetup_and_retrieval = RunnableParallel(\\n    {\"context\": retriever, \"question\": RunnablePassthrough()}\\n)\\n```\\n\\nTo review, the complete chain is:\\n\\n```python\\nsetup_and_retrieval = RunnableParallel(\\n    {\"context\": retriever, \"question\": RunnablePassthrough()}\\n)\\nchain = setup_and_retrieval | prompt | model | output_parser\\n```\\n\\nWith the flow being:\\n\\n1. The first steps create a `RunnableParallel` object with two entries.\\nThe first entry, `context` will include the document results fetched\\nby the retriever. The second entry, `question` will contain the\\nuser‚Äôs original question. To pass on the question, we use\\n`RunnablePassthrough` to copy this entry.\\n\\n2. Feed the dictionary from the step above to the `prompt` component.\\nIt then takes the user input which is `question` as well as the\\nretrieved document which is `context` to construct a prompt and\\noutput a PromptValue.  \\n\\n3. The `model` component takes the generated prompt, and passes into\\nthe OpenAI LLM model for evaluation. The generated output from the\\nmodel is a `ChatMessage` object.\\n\\n4. Finally, the `output_parser` component takes in a `ChatMessage`, and\\ntransforms this into a Python string, which is returned from the\\ninvoke method.\\n\\n## Next steps\\u200b\\n\\nWe recommend reading our [Why use LCEL](/docs/expression_language/why)\\nsection next to see a side-by-side comparison of the code needed to\\nproduce common functionality with and without LCEL.', metadata={'description': 'LCEL makes it easy to build complex chains from basic components, and', 'language': 'en', 'source': 'https://python.langchain.com/docs/expression_language/get_started', 'title': 'Get started | ü¶úÔ∏èüîó Langchain'}),\n",
       " Document(page_content=\"- [LangChain Basics - LLMs & PromptTemplates with Colab](https://youtu.be/J_0qvRt4LNk)\\n- [LangChain Basics - Tools and Chains](https://youtu.be/hI2BY7yl_Ac)\\n- [ChatGPT API Announcement & Code Walkthrough with LangChain](https://youtu.be/phHqvLHCwH4)\\n- [Conversations with Memory (explanation & code walkthrough)](https://youtu.be/X550Zbz_ROE)\\n- [Chat with Flan20B](https://youtu.be/VW5LBavIfY4)\\n- [Using Hugging Face Models locally (code walkthrough)](https://youtu.be/Kn7SX2Mx_Jk)\\n- [PAL: Program-aided Language Models with LangChain code](https://youtu.be/dy7-LvDu-3s)\\n- [Building a Summarization System with LangChain and GPT-3 - Part 1](https://youtu.be/LNq_2s_H01Y)\\n- [Building a Summarization System with LangChain and GPT-3 - Part 2](https://youtu.be/d-yeHDLgKHw)\\n- [Microsoft's Visual ChatGPT using LangChain](https://youtu.be/7YEiEyfPF5U)\\n- [LangChain Agents - Joining Tools and Chains with Decisions](https://youtu.be/ziu87EXZVUE)\\n- [Comparing LLMs with LangChain](https://youtu.be/rFNG0MIEuW0)\\n- [Using Constitutional AI in LangChain](https://youtu.be/uoVqNFDwpX4)\\n- [Talking to Alpaca with LangChain - Creating an Alpaca Chatbot](https://youtu.be/v6sF8Ed3nTE)\\n- [Talk to your CSV & Excel with LangChain](https://youtu.be/xQ3mZhw69bc)\\n- [BabyAGI: Discover the Power of Task-Driven Autonomous Agents!](https://youtu.be/QBcDLSE2ERA)\\n- [Improve your BabyAGI with LangChain](https://youtu.be/DRgPyOXZ-oE)\\n- [Master PDF Chat with LangChain - Your essential guide to queries on documents](https://youtu.be/ZzgUqFtxgXI)\\n- [Using LangChain with DuckDuckGO, Wikipedia & PythonREPL Tools](https://youtu.be/KerHlb8nuVc)\\n- [Building Custom Tools and Agents with LangChain (gpt-3.5-turbo)](https://youtu.be/biS8G8x8DdA)\\n- [LangChain Retrieval QA Over Multiple Files with ChromaDB](https://youtu.be/3yPBVii7Ct0)\\n- [LangChain Retrieval QA with Instructor Embeddings & ChromaDB for PDFs](https://youtu.be/cFCGUjc33aU)\\n- [LangChain + Retrieval Local LLMs for Retrieval QA - No OpenAI!!!](https://youtu.be/9ISVjh8mdlA)\\n- [Camel + LangChain for Synthetic Data & Market Research](https://youtu.be/GldMMK6-_-g)\\n- [Information Extraction with LangChain & Kor](https://youtu.be/SW1ZdqH0rRQ)\\n- [Converting a LangChain App from OpenAI to OpenSource](https://youtu.be/KUDn7bVyIfc)\\n- [Using LangChain Output Parsers to get what you want out of LLMs](https://youtu.be/UVn2NroKQCw)\\n- [Building a LangChain Custom Medical Agent with Memory](https://youtu.be/6UFtRwWnHws)\\n- [Understanding ReACT with LangChain](https://youtu.be/Eug2clsLtFs)\\n- [OpenAI Functions + LangChain : Building a Multi Tool Agent](https://youtu.be/4KXK6c6TVXQ)\\n- [What can you do with 16K tokens in LangChain?](https://youtu.be/z2aCZBAtWXs)\\n- [Tagging and Extraction - Classification using OpenAI Functions](https://youtu.be/a8hMgIcUEnE)\\n- [HOW to Make Conversational Form with LangChain](https://youtu.be/IT93On2LB5k)\", metadata={'description': 'Below are links to tutorials and courses on LangChain. For written guides on common use cases for LangChain, check out the use cases guides.', 'language': 'en', 'source': 'https://python.langchain.com/docs/additional_resources/tutorials', 'title': 'Tutorials | ü¶úÔ∏èüîó Langchain'})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\n",
    "    \"How to create a retriever with lagnchain expression language?\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
