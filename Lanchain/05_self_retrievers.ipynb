{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self Retrievers\n",
    "\n",
    "Un recuperador autoconsultante puede analizar y entender las consultas que se le hacen en lenguaje natural, y luego, puede buscar y filtrar informaci√≥n relevante de su base de datos o documentos almacenados bas√°ndose en esas consultas. Esto lo hace transformando las consultas en un formato estructurado que puede interpretar y procesar de manera eficiente. Esto significa que, adem√°s de comparar la consulta del usuario con los documentos para encontrar coincidencias, tambi√©n puede filtrar los resultados seg√∫n criterios espec√≠ficos extra√≠dos de la consulta del usuario.\n",
    "\n",
    "![Self Retrievers](./diagrams/slide_diagrama_02.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import create_tagging_chain_pydantic\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.indexes import SQLRecordManager, index\n",
    "from langchain.retrievers import SelfQueryRetriever\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import Language, RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from src.langchain_docs_loader import LangchainDocsLoader, num_tokens_from_string\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4398"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.MARKDOWN,\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=50,\n",
    "    length_function=num_tokens_from_string,\n",
    ")\n",
    "\n",
    "loader = LangchainDocsLoader(include_output_cells=False)\n",
    "docs = loader.load()\n",
    "docs = text_splitter.split_documents(docs)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [doc for doc in docs if doc.page_content != \"```\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializado de modelo de lenguaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = ChatOpenAI(temperature=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etiquetado de documentos\n",
    "\n",
    "Los documentos por s√≠ mismos son √∫tiles, pero cuando son etiquetados con informaci√≥n adicional, pueden volverse m√°s √∫tiles. Por ejemplo, si etiquetamos los documentos con su idioma, podemos filtrar los documentos que no est√©n en el idioma que nos interesa. Si etiquetamos los documentos con su tema, podemos filtrar los documentos que no est√©n relacionados con el tema que nos interesa. De esta manera, podemos reducir el espacio de b√∫squeda y obtener mejores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creaci√≥n de esquema de etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'properties': {'code_snippet': {'default': False,\n",
      "                                 'description': 'Whether the text fragment '\n",
      "                                                'includes a code snippet. Code '\n",
      "                                                'snippets are valid markdown '\n",
      "                                                'code blocks.',\n",
      "                                 'title': 'Code Snippet',\n",
      "                                 'type': 'boolean'},\n",
      "                'completness': {'description': 'Describes how useful is the '\n",
      "                                               'text in terms of '\n",
      "                                               'self-explanation. It is '\n",
      "                                               'critical to excel.',\n",
      "                                'enum': ['Very',\n",
      "                                         'Quite',\n",
      "                                         'Medium',\n",
      "                                         'Little',\n",
      "                                         'Not'],\n",
      "                                'title': 'Completness',\n",
      "                                'type': 'string'},\n",
      "                'contains_markdown_table': {'default': False,\n",
      "                                            'description': 'Whether the text '\n",
      "                                                           'fragment contains '\n",
      "                                                           'a markdown table.',\n",
      "                                            'title': 'Contains Markdown Table',\n",
      "                                            'type': 'boolean'},\n",
      "                'description': {'default': False,\n",
      "                                'description': 'Whether the text fragment '\n",
      "                                               'includes a description.',\n",
      "                                'title': 'Description',\n",
      "                                'type': 'boolean'},\n",
      "                'talks_about_chain': {'default': False,\n",
      "                                      'description': 'Whether the text '\n",
      "                                                     'fragment talks about a '\n",
      "                                                     'chain.',\n",
      "                                      'title': 'Talks About Chain',\n",
      "                                      'type': 'boolean'},\n",
      "                'talks_about_expression_language': {'default': False,\n",
      "                                                    'description': 'Whether '\n",
      "                                                                   'the text '\n",
      "                                                                   'fragment '\n",
      "                                                                   'talks '\n",
      "                                                                   'about an '\n",
      "                                                                   'langchain '\n",
      "                                                                   'expression '\n",
      "                                                                   'language.',\n",
      "                                                    'title': 'Talks About '\n",
      "                                                             'Expression '\n",
      "                                                             'Language',\n",
      "                                                    'type': 'boolean'},\n",
      "                'talks_about_retriever': {'default': False,\n",
      "                                          'description': 'Whether the text '\n",
      "                                                         'fragment talks about '\n",
      "                                                         'a retriever.',\n",
      "                                          'title': 'Talks About Retriever',\n",
      "                                          'type': 'boolean'},\n",
      "                'talks_about_vectorstore': {'default': False,\n",
      "                                            'description': 'Whether the text '\n",
      "                                                           'fragment talks '\n",
      "                                                           'about a '\n",
      "                                                           'vectorstore.',\n",
      "                                            'title': 'Talks About Vectorstore',\n",
      "                                            'type': 'boolean'}},\n",
      " 'required': ['completness'],\n",
      " 'title': 'Tags',\n",
      " 'type': 'object'}\n"
     ]
    }
   ],
   "source": [
    "class Tags(BaseModel):\n",
    "    completness: str = Field(\n",
    "        description=\"Describes how useful is the text in terms of self-explanation. It is critical to excel.\",\n",
    "        enum=[\"Very\", \"Quite\", \"Medium\", \"Little\", \"Not\"],\n",
    "    )\n",
    "    code_snippet: bool = Field(\n",
    "        default=False,\n",
    "        description=\"Whether the text fragment includes a code snippet. Code snippets are valid markdown code blocks.\",\n",
    "    )\n",
    "    description: bool = Field(\n",
    "        default=False, description=\"Whether the text fragment includes a description.\"\n",
    "    )\n",
    "    talks_about_vectorstore: bool = Field(\n",
    "        default=False,\n",
    "        description=\"Whether the text fragment talks about a vectorstore.\",\n",
    "    )\n",
    "    talks_about_retriever: bool = Field(\n",
    "        default=False, description=\"Whether the text fragment talks about a retriever.\"\n",
    "    )\n",
    "    talks_about_chain: bool = Field(\n",
    "        default=False, description=\"Whether the text fragment talks about a chain.\"\n",
    "    )\n",
    "    talks_about_expression_language: bool = Field(\n",
    "        default=False,\n",
    "        description=\"Whether the text fragment talks about an langchain expression language.\",\n",
    "    )\n",
    "    contains_markdown_table: bool = Field(\n",
    "        default=False,\n",
    "        description=\"Whether the text fragment contains a markdown table.\",\n",
    "    )\n",
    "\n",
    "\n",
    "pprint(Tags.schema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creaci√≥n de cadena de generaci√≥n de etiquetas (etiquetador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_prompt = \"\"\"Extract the desired information from the following passage.\n",
    "\n",
    "Only extract the properties mentioned in the 'information_extraction' function.\n",
    "Completness should involve more than one sentence.\n",
    "To consider that a passage talks about a property, it is enough that it mentions it once.\n",
    "If there is no mention of a property, set it to False. It only applies for the talk_about_* properties.\n",
    "\n",
    "For instance,\n",
    "To set `talks_about_vectorstore` to True, document should contain the word 'vectorstore' at least once.\n",
    "To set `talks_about_retriever` to True, document should contain the word 'retriever' at least once.\n",
    "To set `talks_about_chain` to True, document should contain the word 'chain' at least once.\n",
    "To set `talks_about_expression_language` to True, document should contain the word 'expression language' or 'LCEL' at least once.\n",
    "\n",
    "Passage:\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "tagging_chain = create_tagging_chain_pydantic(Tags, llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplos de uso del etiquetador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probablemente, un fragmento que √∫nicamente contiene una lista de enlaces a otros fragmentos que tambi√©n se encuentran indexados no es muy √∫til. Esto podr√≠a ocasionar que recuperemos un documento que no es relevante para la consulta, mientras el documento que s√≠ es relevante no se encuentre en los primeros lugares de la lista de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# LangChain cookbook\n",
      "\n",
      "Example code for building applications with LangChain, with an emphasis on more applied and end-to-end examples than contained in the [main documentation](https://python.langchain.com).\n",
      "{'code_snippet': True,\n",
      " 'completness': 'Medium',\n",
      " 'contains_markdown_table': False,\n",
      " 'description': True,\n",
      " 'talks_about_chain': False,\n",
      " 'talks_about_expression_language': False,\n",
      " 'talks_about_retriever': False,\n",
      " 'talks_about_vectorstore': False}\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "\n",
    "result = tagging_chain.invoke(input={\"input\": docs[idx].page_content})\n",
    "print(result.get(\"input\"))\n",
    "pprint(result.get(\"text\").dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un fragmento con enlace a su documentaci√≥n y ejemplo de uso ser√≠a m√°s √∫til."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Example‚Äã\n",
      "\n",
      "To use the Nuclia document loader, you need to instantiate a\n",
      "`NucliaUnderstandingAPI` tool:\n",
      "\n",
      "```python\n",
      "from langchain_community.tools.nuclia import NucliaUnderstandingAPI\n",
      "\n",
      "nua = NucliaUnderstandingAPI(enable_ml=False)\n",
      "```\n",
      "\n",
      "```python\n",
      "from langchain_community.document_loaders.nuclia import NucliaLoader\n",
      "\n",
      "loader = NucliaLoader(\"./interview.mp4\", nua)\n",
      "```\n",
      "\n",
      "You can now call the `load` the document in a loop until you get the\n",
      "document.\n",
      "\n",
      "```python\n",
      "import time\n",
      "\n",
      "pending = True\n",
      "while pending:\n",
      "    time.sleep(15)\n",
      "    docs = loader.load()\n",
      "    if len(docs) > 0:\n",
      "        print(docs[0].page_content)\n",
      "        print(docs[0].metadata)\n",
      "        pending = False\n",
      "    else:\n",
      "        print(\"waiting...\")\n",
      "```\n",
      "{'code_snippet': True,\n",
      " 'completness': 'Very',\n",
      " 'contains_markdown_table': False,\n",
      " 'description': False,\n",
      " 'talks_about_chain': False,\n",
      " 'talks_about_expression_language': False,\n",
      " 'talks_about_retriever': False,\n",
      " 'talks_about_vectorstore': False}\n"
     ]
    }
   ],
   "source": [
    "idx = 1000\n",
    "\n",
    "result = tagging_chain.invoke(input={\"input\": docs[idx].page_content})\n",
    "print(result.get(\"input\"))\n",
    "pprint(result.get(\"text\").dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YdT/AC967vQ/B1paOpgt2ubgf8tZBnafYdB/P3rtbPw+Bhrltx/ur0/OvGxWbxhpTIlUSOK0TwdaWjqYLc3NwP8AlrIM4PsOg/nXa2fh8cNctuP91en51vQWaRIFRAqjsOKsqgUdK+fr4ypVd2zCVRsrQWiRKFRAqjsBirIQKKdRXLuZhRRRSEGKMUUUwEooooAKKKKACiiigAooooGFFFFAB2pKWkoAKKWkoAKKKKACiiigC5RRRWRQUUUUAFFFFABRRRQAlFLSUAFFFFABRRRQAUlLSUAFFFFMQUUUUABANRvCGqSigDKvdKgulxLGCezdCPxrmdS8NP5bqqLcQt96N1BOPp0Nd1jNRvEGrWnXnTejKUmjwXWPANtMzvYMbWYdYnyUz/Mfr9K4\n",
      "{'code_snippet': False,\n",
      " 'completness': 'Not',\n",
      " 'contains_markdown_table': False,\n",
      " 'description': False,\n",
      " 'talks_about_chain': False,\n",
      " 'talks_about_expression_language': False,\n",
      " 'talks_about_retriever': False,\n",
      " 'talks_about_vectorstore': False}\n"
     ]
    }
   ],
   "source": [
    "idx = 1400\n",
    "\n",
    "result = tagging_chain.invoke(input={\"input\": docs[idx].page_content})\n",
    "print(result.get(\"input\"))\n",
    "pprint(result.get(\"text\").dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etiquetado de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Documents with tags: 71'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging_results=tagging_chain.batch(\n",
    "    inputs=[{\"input\":doc.page_content} for doc in docs[:100]],\n",
    "    return_exceptions=True,\n",
    "    config={\"max:concurrency\":50}\n",
    ")\n",
    "\n",
    "docs_with_tags=[\n",
    "\n",
    "]\n",
    "docs_with_tags = [\n",
    "    Document(\n",
    "        page_content=doc.page_content,\n",
    "        metadata={\n",
    "            **doc.metadata,\n",
    "            **result.get(\"text\").dict(),\n",
    "        },\n",
    "    )\n",
    "    for doc, result in zip(docs, tagging_results)\n",
    "    if not isinstance(result, Exception)\n",
    "]\n",
    "\n",
    "f\"Documents with tags: {len(docs_with_tags)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexado de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_added': 71, 'num_updated': 0, 'num_skipped': 0, 'num_deleted': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore = Chroma(\n",
    "    collection_name=\"langchain_docs\",\n",
    "    embedding_function=OpenAIEmbeddings(),\n",
    ")\n",
    "\n",
    "record_manager = SQLRecordManager(\n",
    "    db_url=\"sqlite:///:memory:\",\n",
    "    namespace=\"chroma/langchain_docs\",\n",
    ")\n",
    "\n",
    "record_manager.create_schema()\n",
    "\n",
    "index(\n",
    "    docs_source=docs_with_tags,\n",
    "    record_manager=record_manager,\n",
    "    vector_store=vectorstore,\n",
    "    cleanup=\"full\",\n",
    "    source_id_key=\"source\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recuperaci√≥n de documentos con un `Self Retriever`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creaci√≥n de interfaz de los metadatos disponibles en el √≠ndice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"completness\",\n",
    "        description=\"Describes how useful is the text in terms of self-explanation. It is critical to excel.\",\n",
    "        type='enum=[\"Very\", \"Quite\", \"Medium\", \"Little\", \"Not\"]',\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"code_snippet\",\n",
    "        description=\"Whether the text fragment includes a code snippet. Code snippets are valid markdown code blocks.\",\n",
    "        type=\"bool\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"description\",\n",
    "        description=\"Whether the text fragment includes a description.\",\n",
    "        type=\"bool\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"talks_about_vectorstore\",\n",
    "        description=\"Whether the text fragment talks about a vectorstore.\",\n",
    "        type=\"bool\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"talks_about_retriever\",\n",
    "        description=\"Whether the text fragment talks about a retriever.\",\n",
    "        type=\"bool\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"talks_about_chain\",\n",
    "        description=\"Whether the text fragment talks about a chain.\",\n",
    "        type=\"bool\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"contains_markdown_table\",\n",
    "        description=\"Whether the text fragment contains a markdown table.\",\n",
    "        type=\"bool\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "document_content_description = \"Langchain documentation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creaci√≥n de `retriever`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm=llm,\n",
    "    vectorstore=vectorstore,\n",
    "    document_contents=document_content_description,\n",
    "    metadata_field_info=metadata_field_info,\n",
    "    enable_limit=True,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recuperaci√≥n de documentos con el `retriever`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='```\\n\\n```python\\nfrom langchain.utils.math import cosine_similarity\\nfrom langchain_core.output_parsers import StrOutputParser\\nfrom langchain_core.prompts import PromptTemplate\\nfrom langchain_core.runnables import RunnableLambda, RunnablePassthrough\\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\\n\\nphysics_template = \"\"\"You are a very smart physics professor. \\\\\\nYou are great at answering questions about physics in a concise and easy to understand manner. \\\\\\nWhen you don\\'t know the answer to a question you admit that you don\\'t know.\\n\\nHere is a question:\\n{query}\"\"\"\\n\\nmath_template = \"\"\"You are a very good mathematician. You are great at answering math questions. \\\\\\nYou are so good because you are able to break down hard problems into their component parts, \\\\\\nanswer the component parts, and then put them together to answer the broader question.\\n\\nHere is a question:\\n{query}\"\"\"\\n\\nembeddings = OpenAIEmbeddings()\\nprompt_templates = [physics_template, math_template]\\nprompt_embeddings = embeddings.embed_documents(prompt_templates)\\n\\ndef prompt_router(input):\\n    query_embedding = embeddings.embed_query(input[\"query\"])\\n    similarity = cosine_similarity([query_embedding], prompt_embeddings)[0]\\n    most_similar = prompt_templates[similarity.argmax()]\\n    print(\"Using MATH\" if most_similar == math_template else \"Using PHYSICS\")\\n    return PromptTemplate.from_template(most_similar)\\n\\nchain = (\\n    {\"query\": RunnablePassthrough()}\\n    | RunnableLambda(prompt_router)\\n    | ChatOpenAI()\\n    | StrOutputParser()\\n)\\n```\\n\\n```python\\nprint(chain.invoke(\"What\\'s a black hole\"))\\n```\\n\\n```python\\nprint(chain.invoke(\"What\\'s a path integral\"))\\n```', metadata={'code_snippet': True, 'completness': 'Very', 'contains_markdown_table': True, 'description': True, 'language': 'en', 'source': 'https://python.langchain.com/docs/expression_language/cookbook/embedding_router', 'talks_about_chain': True, 'talks_about_expression_language': True, 'talks_about_retriever': True, 'talks_about_vectorstore': True, 'title': 'Routing by semantic similarity | ü¶úÔ∏èüîó Langchain'}),\n",
       " Document(page_content='# Code writing\\n\\nExample of how to use LCEL to write Python code.\\n\\n```python\\n%pip install --upgrade --quiet  langchain-core langchain-experimental langchain-openai\\n```\\n\\n```python\\nfrom langchain_core.output_parsers import StrOutputParser\\nfrom langchain_core.prompts import (\\n    ChatPromptTemplate,\\n)\\nfrom langchain_experimental.utilities import PythonREPL\\nfrom langchain_openai import ChatOpenAI\\n```\\n\\n```python\\ntemplate = \"\"\"Write some python code to solve the user\\'s problem. \\n\\nReturn only python code in Markdown format, e.g.:\\n\\n```python\\n....\\n```\"\"\"\\nprompt = ChatPromptTemplate.from_messages([(\"system\", template), (\"human\", \"{input}\")])\\n\\nmodel = ChatOpenAI()\\n```\\n\\n```python\\ndef _sanitize_output(text: str):\\n    _, after = text.split(\"```python\")\\n    return after.split(\"```\")[0]\\n```\\n\\n```python\\nchain = prompt | model | StrOutputParser() | _sanitize_output | PythonREPL().run\\n```\\n\\n```python\\nchain.invoke({\"input\": \"whats 2 plus 2\"})\\n```', metadata={'code_snippet': True, 'completness': 'Very', 'contains_markdown_table': True, 'description': True, 'language': 'en', 'source': 'https://python.langchain.com/docs/expression_language/cookbook/code_writing', 'talks_about_chain': True, 'talks_about_expression_language': True, 'talks_about_retriever': True, 'talks_about_vectorstore': True, 'title': 'Code writing | ü¶úÔ∏èüîó Langchain'})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_documents = retriever.get_relevant_documents(\n",
    "    \"useful documents that talk about expression language and retrievers\"\n",
    ")\n",
    "relevant_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='# Code writing\\n\\nExample of how to use LCEL to write Python code.\\n\\n```python\\n%pip install --upgrade --quiet  langchain-core langchain-experimental langchain-openai\\n```\\n\\n```python\\nfrom langchain_core.output_parsers import StrOutputParser\\nfrom langchain_core.prompts import (\\n    ChatPromptTemplate,\\n)\\nfrom langchain_experimental.utilities import PythonREPL\\nfrom langchain_openai import ChatOpenAI\\n```\\n\\n```python\\ntemplate = \"\"\"Write some python code to solve the user\\'s problem. \\n\\nReturn only python code in Markdown format, e.g.:\\n\\n```python\\n....\\n```\"\"\"\\nprompt = ChatPromptTemplate.from_messages([(\"system\", template), (\"human\", \"{input}\")])\\n\\nmodel = ChatOpenAI()\\n```\\n\\n```python\\ndef _sanitize_output(text: str):\\n    _, after = text.split(\"```python\")\\n    return after.split(\"```\")[0]\\n```\\n\\n```python\\nchain = prompt | model | StrOutputParser() | _sanitize_output | PythonREPL().run\\n```\\n\\n```python\\nchain.invoke({\"input\": \"whats 2 plus 2\"})\\n```', metadata={'code_snippet': True, 'completness': 'Very', 'contains_markdown_table': True, 'description': True, 'language': 'en', 'source': 'https://python.langchain.com/docs/expression_language/cookbook/code_writing', 'talks_about_chain': True, 'talks_about_expression_language': True, 'talks_about_retriever': True, 'talks_about_vectorstore': True, 'title': 'Code writing | ü¶úÔ∏èüîó Langchain'}),\n",
       " Document(page_content='```\\n\\n```python\\nfrom langchain.utils.math import cosine_similarity\\nfrom langchain_core.output_parsers import StrOutputParser\\nfrom langchain_core.prompts import PromptTemplate\\nfrom langchain_core.runnables import RunnableLambda, RunnablePassthrough\\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\\n\\nphysics_template = \"\"\"You are a very smart physics professor. \\\\\\nYou are great at answering questions about physics in a concise and easy to understand manner. \\\\\\nWhen you don\\'t know the answer to a question you admit that you don\\'t know.\\n\\nHere is a question:\\n{query}\"\"\"\\n\\nmath_template = \"\"\"You are a very good mathematician. You are great at answering math questions. \\\\\\nYou are so good because you are able to break down hard problems into their component parts, \\\\\\nanswer the component parts, and then put them together to answer the broader question.\\n\\nHere is a question:\\n{query}\"\"\"\\n\\nembeddings = OpenAIEmbeddings()\\nprompt_templates = [physics_template, math_template]\\nprompt_embeddings = embeddings.embed_documents(prompt_templates)\\n\\ndef prompt_router(input):\\n    query_embedding = embeddings.embed_query(input[\"query\"])\\n    similarity = cosine_similarity([query_embedding], prompt_embeddings)[0]\\n    most_similar = prompt_templates[similarity.argmax()]\\n    print(\"Using MATH\" if most_similar == math_template else \"Using PHYSICS\")\\n    return PromptTemplate.from_template(most_similar)\\n\\nchain = (\\n    {\"query\": RunnablePassthrough()}\\n    | RunnableLambda(prompt_router)\\n    | ChatOpenAI()\\n    | StrOutputParser()\\n)\\n```\\n\\n```python\\nprint(chain.invoke(\"What\\'s a black hole\"))\\n```\\n\\n```python\\nprint(chain.invoke(\"What\\'s a path integral\"))\\n```', metadata={'code_snippet': True, 'completness': 'Very', 'contains_markdown_table': True, 'description': True, 'language': 'en', 'source': 'https://python.langchain.com/docs/expression_language/cookbook/embedding_router', 'talks_about_chain': True, 'talks_about_expression_language': True, 'talks_about_retriever': True, 'talks_about_vectorstore': True, 'title': 'Routing by semantic similarity | ü¶úÔ∏èüîó Langchain'})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_documents = retriever.get_relevant_documents(\n",
    "    \"useful documents that talk about expression language and retrievers or vectorstores\"\n",
    ")\n",
    "relevant_documents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
