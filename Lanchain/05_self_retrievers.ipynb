{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self Retrievers\n",
    "\n",
    "Un recuperador autoconsultante puede analizar y entender las consultas que se le hacen en lenguaje natural, y luego, puede buscar y filtrar información relevante de su base de datos o documentos almacenados basándose en esas consultas. Esto lo hace transformando las consultas en un formato estructurado que puede interpretar y procesar de manera eficiente. Esto significa que, además de comparar la consulta del usuario con los documentos para encontrar coincidencias, también puede filtrar los resultados según criterios específicos extraídos de la consulta del usuario.\n",
    "\n",
    "![Self Retrievers](./diagrams/slide_diagrama_02.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import create_tagging_chain_pydantic\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.indexes import SQLRecordManager, index\n",
    "from langchain.retrievers import SelfQueryRetriever\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import Language, RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from src.langchain_docs_loader import LangchainDocsLoader, num_tokens_from_string\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4398"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.MARKDOWN,\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=50,\n",
    "    length_function=num_tokens_from_string,\n",
    ")\n",
    "\n",
    "loader = LangchainDocsLoader(include_output_cells=False)\n",
    "docs = loader.load()\n",
    "docs = text_splitter.split_documents(docs)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [doc for doc in docs if doc.page_content != \"```\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicializado de modelo de lenguaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = ChatOpenAI(temperature=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etiquetado de documentos\n",
    "\n",
    "Los documentos por sí mismos son útiles, pero cuando son etiquetados con información adicional, pueden volverse más útiles. Por ejemplo, si etiquetamos los documentos con su idioma, podemos filtrar los documentos que no estén en el idioma que nos interesa. Si etiquetamos los documentos con su tema, podemos filtrar los documentos que no estén relacionados con el tema que nos interesa. De esta manera, podemos reducir el espacio de búsqueda y obtener mejores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de esquema de etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'properties': {'code_snippet': {'default': False,\n",
      "                                 'description': 'Whether the text fragment '\n",
      "                                                'includes a code snippet. Code '\n",
      "                                                'snippets are valid markdown '\n",
      "                                                'code blocks.',\n",
      "                                 'title': 'Code Snippet',\n",
      "                                 'type': 'boolean'},\n",
      "                'completness': {'description': 'Describes how useful is the '\n",
      "                                               'text in terms of '\n",
      "                                               'self-explanation. It is '\n",
      "                                               'critical to excel.',\n",
      "                                'enum': ['Very',\n",
      "                                         'Quite',\n",
      "                                         'Medium',\n",
      "                                         'Little',\n",
      "                                         'Not'],\n",
      "                                'title': 'Completness',\n",
      "                                'type': 'string'},\n",
      "                'contains_markdown_table': {'default': False,\n",
      "                                            'description': 'Whether the text '\n",
      "                                                           'fragment contains '\n",
      "                                                           'a markdown table.',\n",
      "                                            'title': 'Contains Markdown Table',\n",
      "                                            'type': 'boolean'},\n",
      "                'description': {'default': False,\n",
      "                                'description': 'Whether the text fragment '\n",
      "                                               'includes a description.',\n",
      "                                'title': 'Description',\n",
      "                                'type': 'boolean'},\n",
      "                'talks_about_chain': {'default': False,\n",
      "                                      'description': 'Whether the text '\n",
      "                                                     'fragment talks about a '\n",
      "                                                     'chain.',\n",
      "                                      'title': 'Talks About Chain',\n",
      "                                      'type': 'boolean'},\n",
      "                'talks_about_expression_language': {'default': False,\n",
      "                                                    'description': 'Whether '\n",
      "                                                                   'the text '\n",
      "                                                                   'fragment '\n",
      "                                                                   'talks '\n",
      "                                                                   'about an '\n",
      "                                                                   'langchain '\n",
      "                                                                   'expression '\n",
      "                                                                   'language.',\n",
      "                                                    'title': 'Talks About '\n",
      "                                                             'Expression '\n",
      "                                                             'Language',\n",
      "                                                    'type': 'boolean'},\n",
      "                'talks_about_retriever': {'default': False,\n",
      "                                          'description': 'Whether the text '\n",
      "                                                         'fragment talks about '\n",
      "                                                         'a retriever.',\n",
      "                                          'title': 'Talks About Retriever',\n",
      "                                          'type': 'boolean'},\n",
      "                'talks_about_vectorstore': {'default': False,\n",
      "                                            'description': 'Whether the text '\n",
      "                                                           'fragment talks '\n",
      "                                                           'about a '\n",
      "                                                           'vectorstore.',\n",
      "                                            'title': 'Talks About Vectorstore',\n",
      "                                            'type': 'boolean'}},\n",
      " 'required': ['completness'],\n",
      " 'title': 'Tags',\n",
      " 'type': 'object'}\n"
     ]
    }
   ],
   "source": [
    "class Tags(BaseModel):\n",
    "    completness: str = Field(\n",
    "        description=\"Describes how useful is the text in terms of self-explanation. It is critical to excel.\",\n",
    "        enum=[\"Very\", \"Quite\", \"Medium\", \"Little\", \"Not\"],\n",
    "    )\n",
    "    code_snippet: bool = Field(\n",
    "        default=False,\n",
    "        description=\"Whether the text fragment includes a code snippet. Code snippets are valid markdown code blocks.\",\n",
    "    )\n",
    "    description: bool = Field(\n",
    "        default=False, description=\"Whether the text fragment includes a description.\"\n",
    "    )\n",
    "    talks_about_vectorstore: bool = Field(\n",
    "        default=False,\n",
    "        description=\"Whether the text fragment talks about a vectorstore.\",\n",
    "    )\n",
    "    talks_about_retriever: bool = Field(\n",
    "        default=False, description=\"Whether the text fragment talks about a retriever.\"\n",
    "    )\n",
    "    talks_about_chain: bool = Field(\n",
    "        default=False, description=\"Whether the text fragment talks about a chain.\"\n",
    "    )\n",
    "    talks_about_expression_language: bool = Field(\n",
    "        default=False,\n",
    "        description=\"Whether the text fragment talks about an langchain expression language.\",\n",
    "    )\n",
    "    contains_markdown_table: bool = Field(\n",
    "        default=False,\n",
    "        description=\"Whether the text fragment contains a markdown table.\",\n",
    "    )\n",
    "\n",
    "\n",
    "pprint(Tags.schema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de cadena de generación de etiquetas (etiquetador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_prompt = \"\"\"Extract the desired information from the following passage.\n",
    "\n",
    "Only extract the properties mentioned in the 'information_extraction' function.\n",
    "Completness should involve more than one sentence.\n",
    "To consider that a passage talks about a property, it is enough that it mentions it once.\n",
    "If there is no mention of a property, set it to False. It only applies for the talk_about_* properties.\n",
    "\n",
    "For instance,\n",
    "To set `talks_about_vectorstore` to True, document should contain the word 'vectorstore' at least once.\n",
    "To set `talks_about_retriever` to True, document should contain the word 'retriever' at least once.\n",
    "To set `talks_about_chain` to True, document should contain the word 'chain' at least once.\n",
    "To set `talks_about_expression_language` to True, document should contain the word 'expression language' or 'LCEL' at least once.\n",
    "\n",
    "Passage:\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "tagging_chain = create_tagging_chain_pydantic(Tags, llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplos de uso del etiquetador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probablemente, un fragmento que únicamente contiene una lista de enlaces a otros fragmentos que también se encuentran indexados no es muy útil. Esto podría ocasionar que recuperemos un documento que no es relevante para la consulta, mientras el documento que sí es relevante no se encuentre en los primeros lugares de la lista de resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# LangChain cookbook\n",
      "\n",
      "Example code for building applications with LangChain, with an emphasis on more applied and end-to-end examples than contained in the [main documentation](https://python.langchain.com).\n",
      "{'code_snippet': True,\n",
      " 'completness': 'Medium',\n",
      " 'contains_markdown_table': False,\n",
      " 'description': True,\n",
      " 'talks_about_chain': False,\n",
      " 'talks_about_expression_language': False,\n",
      " 'talks_about_retriever': False,\n",
      " 'talks_about_vectorstore': False}\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "\n",
    "result = tagging_chain.invoke(input={\"input\": docs[idx].page_content})\n",
    "print(result.get(\"input\"))\n",
    "pprint(result.get(\"text\").dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un fragmento con enlace a su documentación y ejemplo de uso sería más útil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Example​\n",
      "\n",
      "To use the Nuclia document loader, you need to instantiate a\n",
      "`NucliaUnderstandingAPI` tool:\n",
      "\n",
      "```python\n",
      "from langchain_community.tools.nuclia import NucliaUnderstandingAPI\n",
      "\n",
      "nua = NucliaUnderstandingAPI(enable_ml=False)\n",
      "```\n",
      "\n",
      "```python\n",
      "from langchain_community.document_loaders.nuclia import NucliaLoader\n",
      "\n",
      "loader = NucliaLoader(\"./interview.mp4\", nua)\n",
      "```\n",
      "\n",
      "You can now call the `load` the document in a loop until you get the\n",
      "document.\n",
      "\n",
      "```python\n",
      "import time\n",
      "\n",
      "pending = True\n",
      "while pending:\n",
      "    time.sleep(15)\n",
      "    docs = loader.load()\n",
      "    if len(docs) > 0:\n",
      "        print(docs[0].page_content)\n",
      "        print(docs[0].metadata)\n",
      "        pending = False\n",
      "    else:\n",
      "        print(\"waiting...\")\n",
      "```\n",
      "{'code_snippet': True,\n",
      " 'completness': 'Very',\n",
      " 'contains_markdown_table': False,\n",
      " 'description': False,\n",
      " 'talks_about_chain': False,\n",
      " 'talks_about_expression_language': False,\n",
      " 'talks_about_retriever': False,\n",
      " 'talks_about_vectorstore': False}\n"
     ]
    }
   ],
   "source": [
    "idx = 1000\n",
    "\n",
    "result = tagging_chain.invoke(input={\"input\": docs[idx].page_content})\n",
    "print(result.get(\"input\"))\n",
    "pprint(result.get(\"text\").dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YdT/AC967vQ/B1paOpgt2ubgf8tZBnafYdB/P3rtbPw+Bhrltx/ur0/OvGxWbxhpTIlUSOK0TwdaWjqYLc3NwP8AlrIM4PsOg/nXa2fh8cNctuP91en51vQWaRIFRAqjsOKsqgUdK+fr4ypVd2zCVRsrQWiRKFRAqjsBirIQKKdRXLuZhRRRSEGKMUUUwEooooAKKKKACiiigAooooGFFFFAB2pKWkoAKKWkoAKKKKACiiigC5RRRWRQUUUUAFFFFABRRRQAlFLSUAFFFFABRRRQAUlLSUAFFFFMQUUUUABANRvCGqSigDKvdKgulxLGCezdCPxrmdS8NP5bqqLcQt96N1BOPp0Nd1jNRvEGrWnXnTejKUmjwXWPANtMzvYMbWYdYnyUz/Mfr9K4\n",
      "{'code_snippet': False,\n",
      " 'completness': 'Not',\n",
      " 'contains_markdown_table': False,\n",
      " 'description': False,\n",
      " 'talks_about_chain': False,\n",
      " 'talks_about_expression_language': False,\n",
      " 'talks_about_retriever': False,\n",
      " 'talks_about_vectorstore': False}\n"
     ]
    }
   ],
   "source": [
    "idx = 1400\n",
    "\n",
    "result = tagging_chain.invoke(input={\"input\": docs[idx].page_content})\n",
    "print(result.get(\"input\"))\n",
    "pprint(result.get(\"text\").dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etiquetado de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Documents with tags: 71'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging_results=tagging_chain.batch(\n",
    "    inputs=[{\"input\":doc.page_content} for doc in docs[:100]],\n",
    "    return_exceptions=True,\n",
    "    config={\"max:concurrency\":50}\n",
    ")\n",
    "\n",
    "docs_with_tags=[\n",
    "\n",
    "]\n",
    "docs_with_tags = [\n",
    "    Document(\n",
    "        page_content=doc.page_content,\n",
    "        metadata={\n",
    "            **doc.metadata,\n",
    "            **result.get(\"text\").dict(),\n",
    "        },\n",
    "    )\n",
    "    for doc, result in zip(docs, tagging_results)\n",
    "    if not isinstance(result, Exception)\n",
    "]\n",
    "\n",
    "f\"Documents with tags: {len(docs_with_tags)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexado de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_added': 71, 'num_updated': 0, 'num_skipped': 0, 'num_deleted': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore = Chroma(\n",
    "    collection_name=\"langchain_docs\",\n",
    "    embedding_function=OpenAIEmbeddings(),\n",
    ")\n",
    "\n",
    "record_manager = SQLRecordManager(\n",
    "    db_url=\"sqlite:///:memory:\",\n",
    "    namespace=\"chroma/langchain_docs\",\n",
    ")\n",
    "\n",
    "record_manager.create_schema()\n",
    "\n",
    "index(\n",
    "    docs_source=docs_with_tags,\n",
    "    record_manager=record_manager,\n",
    "    vector_store=vectorstore,\n",
    "    cleanup=\"full\",\n",
    "    source_id_key=\"source\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recuperación de documentos con un `Self Retriever`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de interfaz de los metadatos disponibles en el índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"completness\",\n",
    "        description=\"Describes how useful is the text in terms of self-explanation. It is critical to excel.\",\n",
    "        type='enum=[\"Very\", \"Quite\", \"Medium\", \"Little\", \"Not\"]',\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"code_snippet\",\n",
    "        description=\"Whether the text fragment includes a code snippet. Code snippets are valid markdown code blocks.\",\n",
    "        type=\"bool\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"description\",\n",
    "        description=\"Whether the text fragment includes a description.\",\n",
    "        type=\"bool\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"talks_about_vectorstore\",\n",
    "        description=\"Whether the text fragment talks about a vectorstore.\",\n",
    "        type=\"bool\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"talks_about_retriever\",\n",
    "        description=\"Whether the text fragment talks about a retriever.\",\n",
    "        type=\"bool\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"talks_about_chain\",\n",
    "        description=\"Whether the text fragment talks about a chain.\",\n",
    "        type=\"bool\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"contains_markdown_table\",\n",
    "        description=\"Whether the text fragment contains a markdown table.\",\n",
    "        type=\"bool\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "document_content_description = \"Langchain documentation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de `retriever`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm=llm,\n",
    "    vectorstore=vectorstore,\n",
    "    document_contents=document_content_description,\n",
    "    metadata_field_info=metadata_field_info,\n",
    "    enable_limit=True,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recuperación de documentos con el `retriever`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='```\\n\\n```python\\nfrom langchain.utils.math import cosine_similarity\\nfrom langchain_core.output_parsers import StrOutputParser\\nfrom langchain_core.prompts import PromptTemplate\\nfrom langchain_core.runnables import RunnableLambda, RunnablePassthrough\\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\\n\\nphysics_template = \"\"\"You are a very smart physics professor. \\\\\\nYou are great at answering questions about physics in a concise and easy to understand manner. \\\\\\nWhen you don\\'t know the answer to a question you admit that you don\\'t know.\\n\\nHere is a question:\\n{query}\"\"\"\\n\\nmath_template = \"\"\"You are a very good mathematician. You are great at answering math questions. \\\\\\nYou are so good because you are able to break down hard problems into their component parts, \\\\\\nanswer the component parts, and then put them together to answer the broader question.\\n\\nHere is a question:\\n{query}\"\"\"\\n\\nembeddings = OpenAIEmbeddings()\\nprompt_templates = [physics_template, math_template]\\nprompt_embeddings = embeddings.embed_documents(prompt_templates)\\n\\ndef prompt_router(input):\\n    query_embedding = embeddings.embed_query(input[\"query\"])\\n    similarity = cosine_similarity([query_embedding], prompt_embeddings)[0]\\n    most_similar = prompt_templates[similarity.argmax()]\\n    print(\"Using MATH\" if most_similar == math_template else \"Using PHYSICS\")\\n    return PromptTemplate.from_template(most_similar)\\n\\nchain = (\\n    {\"query\": RunnablePassthrough()}\\n    | RunnableLambda(prompt_router)\\n    | ChatOpenAI()\\n    | StrOutputParser()\\n)\\n```\\n\\n```python\\nprint(chain.invoke(\"What\\'s a black hole\"))\\n```\\n\\n```python\\nprint(chain.invoke(\"What\\'s a path integral\"))\\n```', metadata={'code_snippet': True, 'completness': 'Very', 'contains_markdown_table': True, 'description': True, 'language': 'en', 'source': 'https://python.langchain.com/docs/expression_language/cookbook/embedding_router', 'talks_about_chain': True, 'talks_about_expression_language': True, 'talks_about_retriever': True, 'talks_about_vectorstore': True, 'title': 'Routing by semantic similarity | 🦜️🔗 Langchain'}),\n",
       " Document(page_content='# Code writing\\n\\nExample of how to use LCEL to write Python code.\\n\\n```python\\n%pip install --upgrade --quiet  langchain-core langchain-experimental langchain-openai\\n```\\n\\n```python\\nfrom langchain_core.output_parsers import StrOutputParser\\nfrom langchain_core.prompts import (\\n    ChatPromptTemplate,\\n)\\nfrom langchain_experimental.utilities import PythonREPL\\nfrom langchain_openai import ChatOpenAI\\n```\\n\\n```python\\ntemplate = \"\"\"Write some python code to solve the user\\'s problem. \\n\\nReturn only python code in Markdown format, e.g.:\\n\\n```python\\n....\\n```\"\"\"\\nprompt = ChatPromptTemplate.from_messages([(\"system\", template), (\"human\", \"{input}\")])\\n\\nmodel = ChatOpenAI()\\n```\\n\\n```python\\ndef _sanitize_output(text: str):\\n    _, after = text.split(\"```python\")\\n    return after.split(\"```\")[0]\\n```\\n\\n```python\\nchain = prompt | model | StrOutputParser() | _sanitize_output | PythonREPL().run\\n```\\n\\n```python\\nchain.invoke({\"input\": \"whats 2 plus 2\"})\\n```', metadata={'code_snippet': True, 'completness': 'Very', 'contains_markdown_table': True, 'description': True, 'language': 'en', 'source': 'https://python.langchain.com/docs/expression_language/cookbook/code_writing', 'talks_about_chain': True, 'talks_about_expression_language': True, 'talks_about_retriever': True, 'talks_about_vectorstore': True, 'title': 'Code writing | 🦜️🔗 Langchain'})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_documents = retriever.get_relevant_documents(\n",
    "    \"useful documents that talk about expression language and retrievers\"\n",
    ")\n",
    "relevant_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='# Code writing\\n\\nExample of how to use LCEL to write Python code.\\n\\n```python\\n%pip install --upgrade --quiet  langchain-core langchain-experimental langchain-openai\\n```\\n\\n```python\\nfrom langchain_core.output_parsers import StrOutputParser\\nfrom langchain_core.prompts import (\\n    ChatPromptTemplate,\\n)\\nfrom langchain_experimental.utilities import PythonREPL\\nfrom langchain_openai import ChatOpenAI\\n```\\n\\n```python\\ntemplate = \"\"\"Write some python code to solve the user\\'s problem. \\n\\nReturn only python code in Markdown format, e.g.:\\n\\n```python\\n....\\n```\"\"\"\\nprompt = ChatPromptTemplate.from_messages([(\"system\", template), (\"human\", \"{input}\")])\\n\\nmodel = ChatOpenAI()\\n```\\n\\n```python\\ndef _sanitize_output(text: str):\\n    _, after = text.split(\"```python\")\\n    return after.split(\"```\")[0]\\n```\\n\\n```python\\nchain = prompt | model | StrOutputParser() | _sanitize_output | PythonREPL().run\\n```\\n\\n```python\\nchain.invoke({\"input\": \"whats 2 plus 2\"})\\n```', metadata={'code_snippet': True, 'completness': 'Very', 'contains_markdown_table': True, 'description': True, 'language': 'en', 'source': 'https://python.langchain.com/docs/expression_language/cookbook/code_writing', 'talks_about_chain': True, 'talks_about_expression_language': True, 'talks_about_retriever': True, 'talks_about_vectorstore': True, 'title': 'Code writing | 🦜️🔗 Langchain'}),\n",
       " Document(page_content='```\\n\\n```python\\nfrom langchain.utils.math import cosine_similarity\\nfrom langchain_core.output_parsers import StrOutputParser\\nfrom langchain_core.prompts import PromptTemplate\\nfrom langchain_core.runnables import RunnableLambda, RunnablePassthrough\\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\\n\\nphysics_template = \"\"\"You are a very smart physics professor. \\\\\\nYou are great at answering questions about physics in a concise and easy to understand manner. \\\\\\nWhen you don\\'t know the answer to a question you admit that you don\\'t know.\\n\\nHere is a question:\\n{query}\"\"\"\\n\\nmath_template = \"\"\"You are a very good mathematician. You are great at answering math questions. \\\\\\nYou are so good because you are able to break down hard problems into their component parts, \\\\\\nanswer the component parts, and then put them together to answer the broader question.\\n\\nHere is a question:\\n{query}\"\"\"\\n\\nembeddings = OpenAIEmbeddings()\\nprompt_templates = [physics_template, math_template]\\nprompt_embeddings = embeddings.embed_documents(prompt_templates)\\n\\ndef prompt_router(input):\\n    query_embedding = embeddings.embed_query(input[\"query\"])\\n    similarity = cosine_similarity([query_embedding], prompt_embeddings)[0]\\n    most_similar = prompt_templates[similarity.argmax()]\\n    print(\"Using MATH\" if most_similar == math_template else \"Using PHYSICS\")\\n    return PromptTemplate.from_template(most_similar)\\n\\nchain = (\\n    {\"query\": RunnablePassthrough()}\\n    | RunnableLambda(prompt_router)\\n    | ChatOpenAI()\\n    | StrOutputParser()\\n)\\n```\\n\\n```python\\nprint(chain.invoke(\"What\\'s a black hole\"))\\n```\\n\\n```python\\nprint(chain.invoke(\"What\\'s a path integral\"))\\n```', metadata={'code_snippet': True, 'completness': 'Very', 'contains_markdown_table': True, 'description': True, 'language': 'en', 'source': 'https://python.langchain.com/docs/expression_language/cookbook/embedding_router', 'talks_about_chain': True, 'talks_about_expression_language': True, 'talks_about_retriever': True, 'talks_about_vectorstore': True, 'title': 'Routing by semantic similarity | 🦜️🔗 Langchain'})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_documents = retriever.get_relevant_documents(\n",
    "    \"useful documents that talk about expression language and retrievers or vectorstores\"\n",
    ")\n",
    "relevant_documents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
